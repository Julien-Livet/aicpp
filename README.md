# aicpp

[![ARC-AGI](https://img.shields.io/badge/Benchmark-ARC--AGI-orange)](https://arcprize.org)
![C++23](https://img.shields.io/badge/C++-23-blue)
![Docker](https://img.shields.io/badge/Docker-ready-blue)
![License](https://img.shields.io/github/license/Julien-Livet/aicpp)
![Python](https://img.shields.io/badge/Python-3.10+-yellow)

**aicpp** is a deterministic symbolic program synthesis engine written in C++, guided by structural reductions generated by large language models (LLMs).

Instead of using LLMs to generate final solutions, aicpp uses them to **reduce the structural search space**, while a native compiled symbolic engine performs bounded-depth exhaustive search.

The goal is to explore a hybrid architecture that balances:

- Determinism  
- Explicability  
- Structural compositionality  
- Native performance  
- Controlled LLM guidance  

[Concept of connected neural network.pdf](https://github.com/user-attachments/files/25365047/Concept.of.connected.neural.network.pdf)

---

## ğŸ§  Core Idea

LLMs are powerful pattern recognizers.

However, instead of letting them directly generate solutions, we use them to:

1. Select relevant primitives  
2. Generate partial structural parameterizations  
3. Reduce combinatorial explosion  

Then a deterministic C++ engine:

- Composes typed primitives
- Explores bounded search depth
- Orders by cost
- Returns explicit symbolic solutions

LLM = structural prior  
C++ engine = deterministic solver  

---

## âœ¨ Features

- âœ” Deterministic exhaustive symbolic exploration
- âœ” Strongly-typed neuron-based architecture
- âœ” Cost-based search ordering
- âœ” Structural partial parameterization via LLM
- âœ” Dynamic C++ code generation and compilation
- âœ” JSON serialization of discovered structures
- âœ” Reusable structural memory
- âœ” Docker reproducibility

---

## ğŸš€ Quick Start

### Using Docker

```bash
ollama pull gpt-oss:20b
git clone https://github.com/Julien-Livet/aicpp.git
cd aicpp
git clone https://github.com/arcprize/ARC-AGI-2.git
docker build -t aicpp .
docker run --rm aicpp
cd scripts
python engine.py
```

---

## ğŸ— Architecture Overview

The system consists of:
1. Primitives (C++)
    - Typed transformation functions
2. Neuron
    - Wraps a primitive function
    - Defines input/output types
3. Connection
    - Composed graph of neurons
    - Brain
    - Manages search space
    - Performs cost-ordered exploration
    - Serializes discovered structures
4. LLM Pipeline (Python)
    - Analyzes ARC task examples
    - Selects relevant primitives
    - Generates structural partials
    - Triggers dynamic compilation
    - Launches exploration

## ğŸ§ª Example (ARC Flip Task)

Given ARC input-output examples, the LLM selects only:
- `flipud`
- `fliplr`

The engine then deterministically explores combinations and returns a symbolic solution such as:
`flipud(fliplr(input))`

No stochastic reasoning occurs in the solving phase.

---

## ğŸ“Š Why This Approach?

Traditional approaches:
- Deep learning â†’ latent, non-explicit
- Program synthesis â†’ combinatorial explosion
- LLM direct generation â†’ non-deterministic

aicpp explores:
    LLM-guided structural reduction + deterministic symbolic completion

This separation preserves:
- Reproducibility
- Inspectability
- Controlled search

## ğŸ“š Documentation
- ğŸ“„ Research positioning: RESEARCH_POSITIONING.md
- ğŸ—º Roadmap: ROADMAP.md
- ğŸ¤ Contribution guidelines: CONTRIBUTING.md
- ğŸ“˜ Conceptual overview (PDF): see README links

---

## ğŸ›  Development

Minimum requirements:
- C++23
- Python 3.10+
- Docker (recommended)

---

## ğŸ”¬ Research Perspective

aicpp is an experimental research framework exploring:
- Structural partial parameterization
- Deterministic symbolic completion
- Hybrid symbolicâ€“LLM architectures
- Combinatorial reduction strategies

It is not a production ARC solver.

---

## ğŸ“ˆ Current Status
- Core engine operational
- ARC flip, color mapping, and segmentation tasks tested
- Structural memory implemented
- Docker reproducibility ensured
- Ongoing combinatorial optimization research

---

## ğŸ¤ Contributing

Please read CONTRIBUTING.md before submitting pull requests.

We welcome contributions in:
- Primitive design
- Search pruning strategies
- Structural compression
- Performance optimization
- ARC benchmarking

---

## ğŸ“œ License

See LICENSE file.

---

## ğŸ§  Vision

aicpp investigates a fundamental hypothesis:
    Large language models are most effective when used as structural reducers,
    not as direct reasoning engines.

The long-term goal is to build scalable, deterministic, and explicable hybrid reasoning systems.
